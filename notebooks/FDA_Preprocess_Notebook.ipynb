{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin working with the FDA recall data, first import the necessary general packages and set your directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "data_dir = os.path.join(wd,\"..\",\"data\")\n",
    "github_data_dir = os.path.join(wd,\"..\",\"github_data\")\n",
    "code_dir = os.path.join(wd,\"..\",\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next import our packages for processing UPCs [Insert Links?] [This will be changed to an import when functions are put in modules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run \"../code/FDA_Preprocess.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import the FDA Recall Press Release Data and FDA Recall Enforcement Report Data, and read them into a Pandas DataFrame. [Give background information or download links here?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "press = pd.read_csv(os.path.join(data_dir, \"FDA_recalls.csv\"),skip_blank_lines = True,encoding='ISO-8859-1')\n",
    "enforce = pd.read_csv(os.path.join(data_dir,\"FDA_food_enforcements_2012-06_to_2016-07.csv\"), encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows in the DataFrame correspond to an individual FDA recall. Each recall is associated with a single company and reason for recall, but may be associated with more than one product. The columns containing the information concerning the recalls vary between the two datasets, with the `enforce` data containing more detailed and FDA-specific information then the `press` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                                      Fri, 01 May 2015 20:41:00 -0400\n",
       "BRAND_NAME                                               Sun Rich, Subway\n",
       "PRODUCT_DESCRIPTION     Apple slices, apple slices with Dip, Sunshine ...\n",
       "REASON                                             Listeria monocytogenes\n",
       "COMPANY                                              Sun Rich Fresh Foods\n",
       "COMPANY_RELEASE_LINK      http://www.fda.gov/Safety/Recalls/ucm445391.htm\n",
       "PHOTOS_LINK             \\r\\t\\t\\thttp://www.fda.gov/Safety/Recalls/ucm4...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product.Type                                                                                     Food\n",
       "Event.ID                                                                                        66563\n",
       "Status                                                                                      Completed\n",
       "Recalling.Firm                                                               Reser's Fine Foods, Inc.\n",
       "Address1                                                                        15570 SW Jenkins Road\n",
       "Address2                                                                                          NaN\n",
       "City                                                                                        Beaverton\n",
       "State.Province                                                                                     OR\n",
       "Postal.Code                                                                                     97006\n",
       "Country                                                                                 United States\n",
       "Voluntary.Mandated                                                          Voluntary: Firm Initiated\n",
       "Initial.Firm.Notification.of.Consignee.or.Public    Two or more of the following: Email, Fax, Lett...\n",
       "Distribution.Pattern                                Distribution was made to AL, AR, AZ, CA, CO, C...\n",
       "Recall.Number                                                                             F-0231-2014\n",
       "Classification                                                                                Class I\n",
       "Product.Description                                 Macaroni Reg CAD, Formula MA.50,  Macaroni Sal...\n",
       "Product.Quantity                                                                                  NaN\n",
       "Reason.for.Recall                                   The recalled products are potentially contamin...\n",
       "Recall.Initiation.Date                                                                     10/22/2013\n",
       "Center.Classification.Date                                                                 12/24/2013\n",
       "Termination.Date                                                                                  NaN\n",
       "Report.Date                                                                                01/01/2014\n",
       "Code.Info                                                            Use by dates: 10/21/13-12/11/13.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enforce.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract UPCs from text fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in processing the FDA data is to extract the UPCs from the text fields they are contained in by making use of the `makeUPCCol` function in the `FDA_Preprocess` module (documenation can be found [HERE]). The function operates in one of two ways depending on what is passed in for `string_list`. These two ways are exemplified by the two different FDA datasets `press` and `enforce`, with the parameter `link` as `True` and `False` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Press Release Dataset (`link = True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Press Release Dataset, the text containing the product information, including UPCs, resides in the page linked to by the URL in the `COMPANY_RELEASE_LINK` column-- the text itself is not contained table.\n",
    "\n",
    "In order to use the `makeUPCCOl` function with this dataset, you must pass `True` for the `link` parameter. This indicates that the `string_list` parameter being passed is a list of URLs rather than a list of strings.  The `makeUPCCol` function calls the `makeUPCList` function for each row in the dataset, and utilizes the Beautiful Soup with an HTML parser to pull out the text contained within the page. The value passed for `link` also indicates the default regex pattern that should be used for finding UPCs within the text. If `link=True` is passed, the default for the pattern parameter is `UPC_PATTERN_PAGE`. This regex pattern is ideal when the text being searched is an XML because it slightly stricter than the `UPC_PATTERN_TEXT` pattern, and is less likely to pull out unrelated number clusters or partial UPCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and append a new column called `upc` to the `press` DataFrame that contains the list of UPCs associated with each recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows processed\n",
      "500 rows processed\n",
      "1000 rows processed\n",
      "1500 rows processed\n",
      "2000 rows processed\n",
      "2500 rows processed\n",
      "3000 rows processed\n",
      "3148 rows processed : COMPLETE\n"
     ]
    }
   ],
   "source": [
    "press[\"upc\"] = makeUPCCol(press[\"COMPANY_RELEASE_LINK\"], link = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>REASON</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>COMPANY_RELEASE_LINK</th>\n",
       "      <th>PHOTOS_LINK</th>\n",
       "      <th>upc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri, 01 May 2015 20:41:00 -0400</td>\n",
       "      <td>Sun Rich, Subway</td>\n",
       "      <td>Apple slices, apple slices with Dip, Sunshine ...</td>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>Sun Rich Fresh Foods</td>\n",
       "      <td>http://www.fda.gov/Safety/Recalls/ucm445391.htm</td>\n",
       "      <td>http://www.fda.gov/Safety/Recalls/ucm445392.htm</td>\n",
       "      <td>[060243004531, 060243004647, 060243012963, 060...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              DATE        BRAND_NAME  \\\n",
       "0  Fri, 01 May 2015 20:41:00 -0400  Sun Rich, Subway   \n",
       "\n",
       "                                 PRODUCT_DESCRIPTION                  REASON  \\\n",
       "0  Apple slices, apple slices with Dip, Sunshine ...  Listeria monocytogenes   \n",
       "\n",
       "                COMPANY                             COMPANY_RELEASE_LINK  \\\n",
       "0  Sun Rich Fresh Foods  http://www.fda.gov/Safety/Recalls/ucm445391.htm   \n",
       "\n",
       "                                       PHOTOS_LINK  \\\n",
       "0  http://www.fda.gov/Safety/Recalls/ucm445392.htm   \n",
       "\n",
       "                                                 upc  \n",
       "0  [060243004531, 060243004647, 060243012963, 060...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforcement Dataset (`link = False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Enforcement data, the product information is contained in strings within the `Code.Info` or `Product.Description` columns. The default parameter `link=False` is the correct value for this dataset, indicating that `string_list` parameter is a list of strings containing the UPCs. When `link=False`, the default parameter for `pattern`, `UPC_PATTERN_TEXT`, is used. This is the optimal pattern when searching strings directly-- it is slightly more liberal with the patterns that it looks for and is able to capture more number clusters without fear of false matches or incomplete UPCs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and append a new column called `upc_pd` to the `enforce` DataFrame that contains the list of UPCs for each recall found in the `Product.Description` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enforce['upcs_pd'] = makeUPCCol(enforce[\"Product.Description\"], verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and append a new column called `upc_ci` to the `enforce` DataFrame that contains the list of UPCs for each recall found in the `Code.Info` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enforce['upcs_ci'] = makeUPCCol(enforce[\"Code.Info\"], verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the `enforce` data is much faster, and there are many more rows, so we pass `verbose=False` to keep the function from printing out status messages.\n",
    "\n",
    "We next combine the UPCs found the `Product.Description` and `Code.Info` columns and obtain a list containing the unique UPCs for each recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append a column called `upc` to the `enforce` DataFrame that contains the list UPCs associated with each recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "union_col = [list(set(enforce.upcs_pd[rownum]).union(set(enforce.upcs_ci[rownum]))) for rownum in range(enforce.shape[0])]\n",
    "enforce['upc'] = pd.Series(union_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, create a list of all of the 12 digit UPCs from an recall event to be used for pattern matching in the UPC processing stage using the `makeEventUPCCol` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enforce[\"event_upc12\"] = makeEventUPCCol(enforce[\"upc\"], enforce[\"Event.ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product.Type</th>\n",
       "      <th>Event.ID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Recalling.Firm</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>City</th>\n",
       "      <th>State.Province</th>\n",
       "      <th>Postal.Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>...</th>\n",
       "      <th>Reason.for.Recall</th>\n",
       "      <th>Recall.Initiation.Date</th>\n",
       "      <th>Center.Classification.Date</th>\n",
       "      <th>Termination.Date</th>\n",
       "      <th>Report.Date</th>\n",
       "      <th>Code.Info</th>\n",
       "      <th>upcs_pd</th>\n",
       "      <th>upcs_ci</th>\n",
       "      <th>upc</th>\n",
       "      <th>event_upc12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food</td>\n",
       "      <td>66563</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reser's Fine Foods, Inc.</td>\n",
       "      <td>15570 SW Jenkins Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beaverton</td>\n",
       "      <td>OR</td>\n",
       "      <td>97006</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>The recalled products are potentially contamin...</td>\n",
       "      <td>10/22/2013</td>\n",
       "      <td>12/24/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2014</td>\n",
       "      <td>Use by dates: 10/21/13-12/11/13.</td>\n",
       "      <td>[071117002164, 071117001631, 052548517571, 071...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[071117002164, 074865208369, 071117001631, 071...</td>\n",
       "      <td>[071117001648, 079453469252, 758108301566, 071...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product.Type  Event.ID     Status            Recalling.Firm  \\\n",
       "0         Food     66563  Completed  Reser's Fine Foods, Inc.   \n",
       "\n",
       "                Address1 Address2       City State.Province Postal.Code  \\\n",
       "0  15570 SW Jenkins Road      NaN  Beaverton             OR       97006   \n",
       "\n",
       "         Country                        ...                          \\\n",
       "0  United States                        ...                           \n",
       "\n",
       "                                   Reason.for.Recall Recall.Initiation.Date  \\\n",
       "0  The recalled products are potentially contamin...             10/22/2013   \n",
       "\n",
       "  Center.Classification.Date Termination.Date Report.Date  \\\n",
       "0                 12/24/2013              NaN  01/01/2014   \n",
       "\n",
       "                           Code.Info  \\\n",
       "0   Use by dates: 10/21/13-12/11/13.   \n",
       "\n",
       "                                             upcs_pd upcs_ci  \\\n",
       "0  [071117002164, 071117001631, 052548517571, 071...      []   \n",
       "\n",
       "                                                 upc  \\\n",
       "0  [071117002164, 074865208369, 071117001631, 071...   \n",
       "\n",
       "                                         event_upc12  \n",
       "0  [071117001648, 079453469252, 758108301566, 071...  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enforce.iloc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Import/Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python lists within Pandas DataFrames are not read in and out as strings, so we created a set of functions to convert between these types more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run \"../code/DataFrame_io.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Data Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First remove escape sequence tokens from the `PHOTOS_LINK` column in the `press` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "photo_col = list()\n",
    "for p_link in press[\"PHOTOS_LINK\"]:\n",
    "    match = re.findall(\"(http.+htm)\", p_link)\n",
    "    if match:\n",
    "        photo_col.append(match[0])\n",
    "    else:\n",
    "        photo_col.append(\"\")\n",
    "press[\"PHOTOS_LINK\"] = pd.Series(photo_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next convert the lists of UPCs in both DataFrames to semi-colon delimited strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "press[\"upc\"] = pd.Series(listToStringCol(press[\"upc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enforce[\"upc\"] = pd.Series(listToStringCol(enforce[\"upc\"]))\n",
    "enforce[\"event_upc12\"] = pd.Series(listToStringCol(enforce[\"event_upc12\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write both DataFrames to CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ignore if you wish to keep the colums showing the UPCs extracted from each column\n",
    "enforce.drop([\"upcs_pd\", \"upcs_ci\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "press.to_csv(\"../github_data/press_upc.csv\")\n",
    "enforce.to_csv(\"../github_data/enforce_upc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSVs into DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "press = pd.read_csv(\"../github_data/press_upc.csv\", index_col = 0).fillna(\"\")\n",
    "enforce = pd.read_csv(\"../github_data/enforce_upc.csv\", index_col = 0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "press[\"upc\"]=pd.Series(stringToListCol(press[\"upc\"]), index = press.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enforce[\"upc\"] = pd.Series(stringToListCol(enforce[\"upc\"]))\n",
    "enforce[\"event_upc12\"] = pd.Series(stringToListCol(enforce[\"event_upc12\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process UPCs and lookup ASINs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next process the UPCs using the `makeUPCProcessedList` function in the `UPC_ASIN_Process` module determine the correct 12-digit UPC, or list of possible 12-digit UPCs for each UPC extracted. This function allows for an optional parameter of `event_upc12_list` to be passed. This is a list of potentially similar UPCs that, through various pattern matching strategies, can be used to determine the correct 12-digit UPC. Then lookup the ASIN for each 12-digit UPC using the `getASIN` function. When processing the UPCs in an entire DataFrame, it is more efficient to use the `makeUPCProcessedASINTuples` function, which processed the UPC and does the ASIN lookup at the same time. The function returns a list of tuples in the format `(row_number, upc_processed_nestedlist, asin_nestedlist)`.  \n",
    "Given the large number of UPCs and the API rate rate limit of 1 query per second, this process takes a significant period of time. It is therefore encouraged to pass the `pickle=True` (as well as `verbose=True` in order to keep track of the functions progress) parameter. The function will then use the Python pickling process (https://docs.python.org/3/library/pickle.html) to update and save the list of tuples to the file `data_pickle` every 200 rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run \"../code/UPC_ASIN_Process.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First process the press data, passing the name of the DataFrame, the name of the column containing the UPCs, and both pickle and verbose as True. The parameter `event_upc12_colname` is left at the default value of `None`, indicating that the list of potentially similar UPCs to be used for pattern matching should be constructed from all of the 12-digit UPCs from the same FDA recall. The `rowrange` parameter is also left at the default, indicating that the entire DataFrame should be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Console output not shown\n",
    "press_tuple_list = makeUPCProcessedASINTuples(press, \"upc\", pickle = True, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the process is complete (the last line printed should read: `3154 rows processed & saved`), the processed tuples should be stored in `press_tuples` as well as `data_pickle`. MAKE SURE TO RENAME THE PICKLE FILE IMMIDIATELY SO THE FILE WILL NOT BE OVERWRITTEN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.rename('data_pickle', 'press_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the pickled file and check the first tuple and the length of the list to ensure that the process went smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('press_pickle', 'rb') as file:\n",
    "    press_tuples = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [['060243004531'],\n",
       "  ['060243004647'],\n",
       "  ['060243012963'],\n",
       "  ['060243012932'],\n",
       "  ['060243005088'],\n",
       "  ['060243004586']],\n",
       " [['B00D4KXTAG'],\n",
       "  ['UPCNOTFOUND'],\n",
       "  ['B01785QBMU'],\n",
       "  ['B00P150LIA'],\n",
       "  ['B00BTGKHC0'],\n",
       "  ['B00TIYSSTE']])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3154"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(press_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then repeat the process with the enforce data. This time, pass the `event_upc12_colname` as `event_upc12`, which was prepared in the FDA Preprocessing section above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Console output not shown\n",
    "enforce_tuple_list = makeUPCProcessedASINTuples(enforce, \"upc\", event_upc12_colname = \"event_upc12\", pickle = True, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your notebook stops running, or a error is thrown by the API, the pickling and saving process ensures that the work is not lost and one can more or less pick up where they left off. The last save point can be determined either from the last the status printed to the console (e.g. `3200 rows processed & saved`) or by reading in the pickle file and checking the length or indices. Indices are included in the tuples in order to make processing the data in pieces and later recombining simpler and easier to check. Again, be sure and rename the pickle file before proceeding with the rest of the data processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_pickle', 'rb') as file:\n",
    "    enforce_tuples_1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3199,\n",
       " [['053000011149', '753000011148', '853000011145', '653000011141']],\n",
       " [['B000TQHTPE', 'UPCNOTFOUND', 'UPCNOTFOUND', 'UPCNOTFOUND']])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enforce_tuples_1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.rename('data_pickle', 'enforce_pickle_0_3200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the `rowrange` parameter as a (`first_row','last_row`) tuple in order to continue from the last save point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enforce_tuple_list = makeUPCProcessedASINTuples(enforce, \"upc\", event_upc12_colname = \"event_upc12\", rowrange = (3200, enforce.shape[0]), pickle = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.rename('data_pickle', 'enforce_pickle_3200_end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the pickle file(s), combine the lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('enforce_pickle_3200_end', 'rb') as file:\n",
    "    enforce_tuples_2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enforce_tuples = enforce_tuples_1+enforce_tuples_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next read the tuple lists into Pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "press_codes_df = pd.DataFrame.from_records(press_tuples, columns = [\"row\", \"upc_processed\", \"asin\"])\n",
    "enforce_codes_df = pd.DataFrame.from_records(enforce_tuples, columns = [\"row\", \"upc_processed\", \"asin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the index and `row` columns match-- this is a good check to make sure that recombining the lists worked correctly. The redundant `row` columns can then be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>upc_processed</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[071117002164], [074865208369], [071117001631...</td>\n",
       "      <td>[[B00JVD5VMY], [B00V6WFALA], [B01EX9EHUM], [B0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row                                      upc_processed  \\\n",
       "0    0  [[071117002164], [074865208369], [071117001631...   \n",
       "\n",
       "                                                asin  \n",
       "0  [[B00JVD5VMY], [B00V6WFALA], [B01EX9EHUM], [B0...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enforce_codes_df.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "press_codes_df.drop([\"row\"], axis = 1, inplace = True)\n",
    "enforce_codes_df.drop([\"row\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Unfortunately, for a variety of reasons, querying the API for the ASIN does not always work correctly, and the response can be a long error code rather than than the 10 character ASIN or `UPCNOTFOUND`. Instead of querying the the API again if it returns a \"error string\", it is far more efficient to look for and fix these after the initial processing is complete. \n",
    "Use the `fixASINErrors` function on both DataFrames. This should fix all of the error strings, but this can be double checked by running the function again and checking that `0 Error Strings found and fixed` is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Error Strings found and fixed\n"
     ]
    }
   ],
   "source": [
    "press_codes_df[\"asin\"] = fixASINErrors(press_codes_df[\"asin\"], press_codes_df[\"upc_processed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Error Strings found and fixed\n"
     ]
    }
   ],
   "source": [
    "enforce_codes_df[\"asin\"] = fixASINErrors(enforce_codes_df[\"asin\"], enforce_codes_df[\"upc_processed\"])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
